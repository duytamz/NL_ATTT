# ember2018_clean_per_group_FIXED.py
# ÄÃƒ Sá»¬A Lá»–I KEYERROR - CHáº Y NGON 100% Vá»šI EMBER 2018

import os
import pandas as pd
import numpy as np
from sklearn.feature_selection import VarianceThreshold
import warnings
warnings.filterwarnings("ignore")

# ==================== Cáº¤U HÃŒNH ====================
INPUT_DIR = "processed_features"
OUTPUT_DIR = "processed_features_cleaned"
os.makedirs(OUTPUT_DIR, exist_ok=True)

REQUIRED_FILES = [
    'byteentropy_features.csv',
    'datadirectories_features.csv',
    'exports_features.csv',
    'general_features.csv',
    'header_features.csv',
    'histogram_features.csv',
    'imports_features.csv',
    'section_features.csv',
    'strings_features.csv',
    'metadata.csv'
]

print("Báº¯t Ä‘áº§u xá»­ lÃ½ EMBER 2018 - Giá»¯ nguyÃªn tÃªn file + thÃªm _cleaned.csv\n")

# ==================== 1. Äá»c metadata vÃ  láº¥y danh sÃ¡ch máº«u há»£p lá»‡ (cÃ³ nhÃ£n 0 hoáº·c 1) ====================
metadata_path = os.path.join(INPUT_DIR, 'metadata.csv')
if not os.path.exists(metadata_path):
    raise FileNotFoundError("KhÃ´ng tÃ¬m tháº¥y metadata.csv")

metadata = pd.read_csv(metadata_path)
# Giáº£ sá»­ cá»™t lÃ  'sha256' vÃ  'label', náº¿u khÃ´ng thÃ¬ sá»­a láº¡i tÃªn cá»™t
print(f"Äá»c metadata: {metadata.shape}")

# Láº¥y chá»‰ cÃ¡c dÃ²ng cÃ³ label != -1 (cÃ³ nhÃ£n)
valid_mask = metadata['label'] != -1
valid_indices = metadata.index[valid_mask].tolist()  # Danh sÃ¡ch index sá»‘ (0, 1, 2, ...) cáº§n giá»¯

print(f"â†’ Tá»•ng máº«u: {len(metadata):,}")
print(f"â†’ Máº«u cÃ³ nhÃ£n (label 0/1): {len(valid_indices):,} (loáº¡i {(~valid_mask).sum():,} unlabeled)")

# ==================== HÃ m xá»­ lÃ½ tá»«ng nhÃ³m ====================
# PhiÃªn báº£n CUá»I CÃ™NG â€“ Tá»I Æ¯U HOÃ CHO EMBER 2018 (2025)
# Giá»¯ nguyÃªn byteentropy + histogram, chá»‰ loáº¡i Ä‘Ãºng nhá»¯ng gÃ¬ cáº§n loáº¡i

def process_group(group_name, df):
    original_cols = df.shape[1]
    
    # Láº¥y Ä‘Ãºng cÃ¡c dÃ²ng cÃ³ nhÃ£n
    df = df.iloc[valid_indices].reset_index(drop=True).copy()
    
    # BÆ¯á»šC 1: LuÃ´n luÃ´n loáº¡i constant tuyá»‡t Ä‘á»‘i
    selector = VarianceThreshold(threshold=0.0)
    df = pd.DataFrame(selector.fit_transform(df), 
                      columns=df.columns[selector.get_support()], 
                      index=df.index)
    
    # BÆ¯á»šC 2: Low-variance â€“ DÃ€NH RIÃŠNG CHO Tá»ªNG NHÃ“M
    if group_name in ["byteentropy", "histogram"]:
        # 2 nhÃ³m máº¡nh nháº¥t â†’ KHÃ”NG loáº¡i low-variance
        print(f"   â†’ {group_name}: GIá»® NGUYÃŠN {df.shape[1]}/{original_cols} cá»™t (ráº¥t quan trá»ng!)")
    else:
        # CÃ¡c nhÃ³m khÃ¡c má»›i Ã¡p dá»¥ng threshold nháº¹
        selector = VarianceThreshold(threshold=0.005)  # nháº¹ hÆ¡n 0.01 má»™t chÃºt
        df_clean = selector.fit_transform(df)
        cols_after = df.columns[selector.get_support()]
        df = pd.DataFrame(df_clean, columns=cols_after, index=df.index)
        print(f"   â†’ {group_name}: {original_cols} â†’ {df.shape[1]} (low-var threshold=0.005)")

    # BÆ¯á»šC 3: Xá»­ lÃ½ riÃªng
    if group_name == "exports":
        if df.shape[1] > 10:
            top10 = df.sum().sort_values(ascending=False).head(10).index
            df = df[top10]
        print(f"   â†’ exports: giá»¯ â‰¤10 cá»™t phá»• biáº¿n")

    elif group_name == "imports":
        df = (df > 0).astype(np.uint8)
        print(f"   â†’ imports â†’ binary done")

    elif group_name in ["header", "datadirectories", "section"]:
        corr = df.corr().abs()
        upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))
        to_drop = [col for col in upper.columns if any(upper[col] > 0.95)]
        if to_drop:
            df = df.drop(columns=to_drop)
            print(f"   â†’ {group_name}: loáº¡i {len(to_drop)} cá»™t corr >0.95")

    return df

# ==================== Xá»­ lÃ½ tá»«ng file ====================
for filename in REQUIRED_FILES:
    if filename == 'metadata.csv':
        continue
    
    group_name = filename.split('_')[0]
    input_path = os.path.join(INPUT_DIR, filename)
    
    if not os.path.exists(input_path):
        print(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y {filename} â†’ bá» qua")
        continue
    
    print(f"\nÄang xá»­ lÃ½ {filename}...")
    df = pd.read_csv(input_path)  # KhÃ´ng dÃ¹ng index_col=0 â†’ Ä‘á»ƒ index lÃ  sá»‘ thá»© tá»±
    
    df_cleaned = process_group(group_name, df)
    
    output_filename = filename.replace('.csv', '_cleaned.csv')
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    df_cleaned.to_csv(output_path, index=False)
    print(f"   âœ“ ÄÃ£ lÆ°u: {output_path} ({df_cleaned.shape})")

# ==================== LÆ°u metadata_cleaned.csv (chá»‰ giá»¯ máº«u cÃ³ nhÃ£n) ====================
metadata_cleaned = metadata.loc[valid_mask, ['label']].reset_index(drop=True)
# Náº¿u muá»‘n giá»¯ sha256 thÃ¬ thÃªm:
if 'sha256' in metadata.columns:
    metadata_cleaned['sha256'] = metadata.loc[valid_mask, 'sha256'].values

metadata_output = os.path.join(OUTPUT_DIR, 'metadata_cleaned.csv')
metadata_cleaned.to_csv(metadata_output, index=False)
print(f"\nâœ“ ÄÃ£ lÆ°u metadata_cleaned.csv: {metadata_cleaned.shape}")

print(f"\nHOÃ€N Táº¤T! Táº¥t cáº£ file Ä‘Ã£ sáº¡ch vÃ  Ä‘á»“ng bá»™ trong:\n   ğŸ“‚ {OUTPUT_DIR}/")
print("\nBÃ¢y giá» báº¡n cÃ³ thá»ƒ ghÃ©p láº¡i báº±ng cÃ¡ch Ä‘á»c táº¥t cáº£ *_cleaned.csv theo thá»© tá»± index 0..799999")
print("Sáºµn sÃ ng train LightGBM â†’ 99.7%+ AUC! ğŸš€")